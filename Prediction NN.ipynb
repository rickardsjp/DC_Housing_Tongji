{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Lambda, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot\n",
    "data = pd.get_dummies(data, prefix = [\"HEAT\", \"AC\", \"QUALIFIED\", \"STYLE\", \"STRUCT\", \"GRADE\", \"CNDTN\", \"EXTWALL\", \"INTWALL\", \"ROOF\", \"ASSESSMENT_SUBNBHD\"], columns = [\"HEAT\", \"AC\", \"QUALIFIED\", \"STYLE\", \"STRUCT\", \"GRADE\", \"CNDTN\", \"EXTWALL\", \"INTWALL\", \"ROOF\", \"ASSESSMENT_SUBNBHD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split\n",
    "x_data = data.drop([\"PRICE\"], axis=1)\n",
    "y_data = data[\"PRICE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "x_data = x_data.astype(float)\n",
    "x_data = x_data.apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train & test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_72 (Dense)             (None, 2048)              518144    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,879,745\n",
      "Trainable params: 4,871,553\n",
      "Non-trainable params: 8,192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2048, activation=\"tanh\", kernel_initializer='normal', input_shape=(252,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation=\"tanh\", kernel_initializer='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation=\"tanh\", kernel_initializer='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation=\"relu\", kernel_initializer='normal', \n",
    "    kernel_regularizer=regularizers.l1(0.02), bias_regularizer=regularizers.l1(0.02)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation=\"relu\", kernel_initializer='normal', \n",
    "    kernel_regularizer=regularizers.l1_l2(0.02), bias_regularizer=regularizers.l1_l2(0.02)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation=\"relu\", kernel_initializer='normal'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1))\n",
    "model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='nadam',\n",
    "    metrics=[\"mae\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52058 samples, validate on 25641 samples\n",
      "Epoch 1/40\n",
      "52058/52058 [==============================] - 114s 2ms/step - loss: 297741453594.8599 - mean_absolute_error: 241946.4750 - val_loss: 221320647473.2511 - val_mean_absolute_error: 185198.2909\n",
      "Epoch 2/40\n",
      "52058/52058 [==============================] - 105s 2ms/step - loss: 238141351485.8633 - mean_absolute_error: 201669.9293 - val_loss: 203468146658.3675 - val_mean_absolute_error: 186948.9053\n",
      "Epoch 3/40\n",
      "52058/52058 [==============================] - 1004s 19ms/step - loss: 229705956406.4869 - mean_absolute_error: 202985.5877 - val_loss: 202273203765.7739 - val_mean_absolute_error: 169992.4053\n",
      "Epoch 4/40\n",
      "52058/52058 [==============================] - 107s 2ms/step - loss: 226919700261.3442 - mean_absolute_error: 200369.1451 - val_loss: 190369163004.4157 - val_mean_absolute_error: 169439.8412\n",
      "Epoch 5/40\n",
      "52058/52058 [==============================] - 109s 2ms/step - loss: 219841757612.0272 - mean_absolute_error: 199448.6592 - val_loss: 190645660373.3982 - val_mean_absolute_error: 168603.8833\n",
      "Epoch 6/40\n",
      "52058/52058 [==============================] - 104s 2ms/step - loss: 217149959043.7226 - mean_absolute_error: 195036.7327 - val_loss: 199378821800.9095 - val_mean_absolute_error: 176165.7003\n",
      "Epoch 7/40\n",
      "52058/52058 [==============================] - 142s 3ms/step - loss: 219669391180.5276 - mean_absolute_error: 196245.9282 - val_loss: 181192974005.8088 - val_mean_absolute_error: 164705.9162\n",
      "Epoch 8/40\n",
      "48256/52058 [==========================>...] - ETA: 7s - loss: 201529981639.6393 - mean_absolute_error: 191900.6580"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "history = model.fit(x_train, \n",
    "          y_train,\n",
    "          batch_size = 128,\n",
    "          shuffle = True,\n",
    "          epochs = 40,\n",
    "          validation_data = (x_test, y_test),\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "valid_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('Train MAE: ', round(train_score[1], 4), ', Train Loss: ', round(train_score[0], 4)) \n",
    "print('Val MAE: ', round(valid_score[1], 4), ', Val Loss: ', round(valid_score[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_pred, c='black')\n",
    "line = mlines.Line2D([0, 1], [0, 1], color='red')\n",
    "transform = ax.transAxes\n",
    "line.set_transform(transform)\n",
    "plt.xlim(0, 2000000)\n",
    "plt.ylim(0, 2000000)\n",
    "ax.add_line(line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(h, xsize=6, ysize=10):\n",
    "    # Prepare plotting\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    plt.rcParams[\"figure.figsize\"] = [xsize, ysize]\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=4, sharex=True)\n",
    "    \n",
    "    # summarize history for MAE\n",
    "    plt.subplot(211)\n",
    "    plt.plot(h['mean_absolute_error'])\n",
    "    plt.plot(h['val_mean_absolute_error'])\n",
    "    plt.title('Training vs Validation MAE')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.subplot(212)\n",
    "    plt.plot(h['loss'])\n",
    "    plt.plot(h['val_loss'])\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # Plot it all in IPython (non-interactive)\n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "plot_hist(history.history, xsize=8, ysize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
