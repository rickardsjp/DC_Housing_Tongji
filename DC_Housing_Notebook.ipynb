{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/DC_Properties.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape # we have 49 columns and 158957 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "\n",
    "print(\"Row Count: \" + str(data.shape[0]))\n",
    "print()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data[\"STYLE\"].notnull()].shape # 52.261 rows don't have a value for the \"STYLE\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"STRUCT\"].notnull() | data[\"STYLE\"].notnull() | data[\"GRADE\"].notnull() | data[\"CNDTN\"].notnull() | data[\"EXTWALL\"].notnull() | data[\"ROOF\"].notnull() | data[\"INTWALL\"].notnull()].shape # the same rows don't have a value for: \"STRUCT\", \"GRADE\", \"CNDTN\", \"EXTWALL\", \"ROOF\", \"INTWALL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# command copied form data cleaning\n",
    "data_dropped_rows = data[data[\"STRUCT\"].notnull() | data[\"STYLE\"].notnull() | data[\"GRADE\"].notnull() | data[\"CNDTN\"].notnull() | data[\"EXTWALL\"].notnull() | data[\"ROOF\"].notnull() | data[\"INTWALL\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data_dropped_rows.isnull().sum()\n",
    "\n",
    "print(\"Row Count: \" + str(data_dropped_rows.shape[0]))\n",
    "print()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) no row has a value for the cmplx_num and the living_gba => useless\n",
    "2) there are many missing values for the sale_date and the yr_rmdl => maybe they aren't missing, it could be the case, that these houses were never remodeled and/ or sold before, in the following we will probably handle them this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a column called \"Unnamed: 0\", lets see what's in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's just the same as the index (probably the unique id column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"STATE\"].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"CITY\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset is only about Washington DC these columns habe no use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"ZIPCODE\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ZIPCODE on the otherside contains some value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"FULLADDRESS\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"FULLADDRESS\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0] - data[\"FULLADDRESS\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column \"FULLADDRESS\" has only unique text values, the computer can't process them. Either you split them up (street and house number or just leave them out because the streetnames aren't that useful either)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"NATIONALGRID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"NATIONALGRID\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0] - data[\"NATIONALGRID\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column \"NATIONALGRID\" has the same problem, as the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"GIS_LAST_MOD_DTTM\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This row says when the row of the dataset was last modified, it's useless for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SALEDATE\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This row contains the date, the building was sold. The way it is saved is not good to compute, we will convert it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "\n",
    "data.boxplot(column=[\"PRICE\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.sort_values(by=\"PRICE\")[\"PRICE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The price of some buildings is suspicous, we have some verry verry high prices (140.000.000$) and some realy low prices (1$) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "\n",
    "data.loc[(data[\"PRICE\"] <= 25000000) & (data[\"PRICE\"] >= 60000)].boxplot(column=[\"PRICE\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"AC\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A zero in there is strange value it stands for NULL, therefore we should replace it with NULL instead of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"BLDG_NUM\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't found anything about this column in the documentation and since it has only two possible values, it seems kind of useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command will throw away ~33% of the data (maybe we will keep the data and do two seperate tests, one where we will throw away the rows where the data is missing and one where we will throw away these columns)\n",
    "# data = data[data[\"STRUCT\"].notnull() | data[\"STYLE\"].notnull() | data[\"GRADE\"].notnull() | data[\"CNDTN\"].notnull() | data[\"EXTWALL\"].notnull() | data[\"ROOF\"].notnull() | data[\"INTWALL\"].notnull()]\n",
    "\n",
    "# since our many concern is the price of the building, rows without the price have only a small to none value\n",
    "data = data[data[\"PRICE\"].notnull()]\n",
    "\n",
    "# remove rows with strange prices\n",
    "data = data.loc[(data[\"PRICE\"] <= 25000000) & (data[\"PRICE\"] >= 60000)]\n",
    "\n",
    "# in these very few rows (~200) there are values missing\n",
    "data = data[data[\"X\"].notnull() & data[\"Y\"].notnull() & data[\"QUADRANT\"].notnull() & data[\"AYB\"].notnull() & data[\"WARD\"].notnull() & data[\"ASSESSMENT_NBHD\"].notnull() & data[\"CENSUS_TRACT\"].notnull() & data[\"LONGITUDE\"].notnull() & data[\"LATITUDE\"].notnull() & data[\"ZIPCODE\"].notnull()]\n",
    "data = data[data.ROOMS != 0]\n",
    "data = data[data.AC != \"0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this column has only one value \"2018-07-22 18:01:43\" => useless\n",
    "data = data.drop([\"GIS_LAST_MOD_DTTM\"], axis=1)\n",
    "# since the unique id is equal to the row number we don't need it\n",
    "data = data.drop([\"Unnamed: 0\"], axis=1)\n",
    "# many many missing values\n",
    "data = data.drop([\"LIVING_GBA\", \"CMPLX_NUM\"], axis=1)\n",
    "# these columns have nothing to say\n",
    "data = data.drop([\"STATE\", \"CITY\", \"SOURCE\", \"BLDG_NUM\"], axis=1)\n",
    "# these columns contain only unique texts which can't be computed\n",
    "data = data.drop([\"NATIONALGRID\", \"FULLADDRESS\"], axis=1)\n",
    "# in our other notebook we proved that there is a realy high (< 0.999) correlation between x, y and longitude and latititude because in both show the longitude and latitdude of a building\n",
    "data = data.drop([\"X\", \"Y\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the missing sale date to the year it was build\n",
    "data[\"SALEDATE\"] = np.where(data[\"SALEDATE\"].isnull(), data[\"AYB\"], data[\"SALEDATE\"])\n",
    "\n",
    "# add a column wich says wether a building was remodeled and insert missing values in to the YR_RMDL column\n",
    "data[\"WAS_REMODELED\"] = np.where(data[\"YR_RMDL\"].isnull(), 0, 1)\n",
    "data[\"YR_RMDL\"] = np.where(data[\"YR_RMDL\"].isnull(), -1, data[\"YR_RMDL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert saledate to datetime\n",
    "data['SALEDATE'] = pd.to_datetime(data['SALEDATE'])\n",
    "#Calculating the difference in years between Last Sale Date and Year Built\n",
    "data['SalevYB']=data['SALEDATE'].dt.year - data['AYB']\n",
    "#Calculating the difference in years between Last Sale Date and Year Improved\n",
    "data['SalevYI']=data['SALEDATE'].dt.year - data['EYB']\n",
    "\n",
    "data = data.drop([\"SALEDATE\", \"EYB\", \"AYB\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "print(\"All Data:\")\n",
    "print(\"Row Count: \" + str(data.shape[0]))\n",
    "print(\"Col Count: \" + str(data.shape[1]))\n",
    "print()\n",
    "print(missing_values)\n",
    "\n",
    "data_col = data.drop([\"NUM_UNITS\", \"STORIES\", \"GBA\", \"STYLE\", \"STRUCT\", \"GRADE\", \"CNDTN\", \"EXTWALL\", \"ROOF\", \"INTWALL\", \"KITCHENS\", \"ASSESSMENT_SUBNBHD\", \"CENSUS_BLOCK\"], axis=1)\n",
    "missing_values_col = data_col.isnull().sum()\n",
    "print()\n",
    "print(\"--------------------------------------------------\")\n",
    "print()\n",
    "print(\"Data with dropped columns:\")\n",
    "print(\"Row Count: \" + str(data_col.shape[0]))\n",
    "print(\"Col Count: \" + str(data_col.shape[1]))\n",
    "print()\n",
    "print(missing_values_col)\n",
    "\n",
    "data_row = data[data[\"STRUCT\"].notnull() & data[\"STYLE\"].notnull() & data[\"GRADE\"].notnull() & data[\"CNDTN\"].notnull() & data[\"EXTWALL\"].notnull() & data[\"ROOF\"].notnull() & data[\"INTWALL\"].notnull()  & data[\"STORIES\"].notnull() & data[\"KITCHENS\"].notnull() & data[\"ASSESSMENT_SUBNBHD\"].notnull()  & data[\"CENSUS_BLOCK\"].notnull()]\n",
    "missing_values_row = data_row.isnull().sum()\n",
    "print()\n",
    "print(\"--------------------------------------------------\")\n",
    "print()\n",
    "print(\"Data with dropped rows:\")\n",
    "print(\"Row Count: \" + str(data_row.shape[0]))\n",
    "print(\"Col Count: \" + str(data_row.shape[1]))\n",
    "print()\n",
    "print(missing_values_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_row.to_csv(\"data/data_cleaned_row.csv\", index=False)\n",
    "data_col.to_csv(\"data/data_cleaned_col.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subsample (for faster development -> remove (comment out) later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding (needed for the nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_row_one_hot = pd.get_dummies(data_row, prefix = [\"HEAT\", \"AC\", \"QUALIFIED\", \"STYLE\", \"STRUCT\", \"GRADE\", \"CNDTN\", \"EXTWALL\", \"INTWALL\", \"ROOF\", \"ZIPCODE\", \"ASSESSMENT_NBHD\", \"ASSESSMENT_SUBNBHD\", \"CENSUS_TRACT\", \"CENSUS_BLOCK\", \"WARD\", \"QUADRANT\", \"WAS_REMODELED\"], columns = [\"HEAT\", \"AC\", \"QUALIFIED\", \"STYLE\", \"STRUCT\", \"GRADE\", \"CNDTN\", \"EXTWALL\", \"INTWALL\", \"ROOF\", \"ZIPCODE\", \"ASSESSMENT_NBHD\", \"ASSESSMENT_SUBNBHD\", \"CENSUS_TRACT\", \"CENSUS_BLOCK\", \"WARD\", \"QUADRANT\", \"WAS_REMODELED\"])\n",
    "data_col_one_hot = pd.get_dummies(data_col, prefix = [\"HEAT\", \"AC\", \"QUALIFIED\", \"ZIPCODE\", \"ASSESSMENT_NBHD\", \"CENSUS_TRACT\", \"WARD\", \"QUADRANT\", \"WAS_REMODELED\"], columns = [\"HEAT\", \"AC\", \"QUALIFIED\", \"ZIPCODE\", \"ASSESSMENT_NBHD\", \"CENSUS_TRACT\", \"WARD\", \"QUADRANT\", \"WAS_REMODELED\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove categorical data (needed for regression analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_row_no_cat = data_row\n",
    "data_col_no_cat = data_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_row_no_cat = data_row_no_cat.drop([\"HEAT\", \"AC\", \"QUALIFIED\", \"STYLE\", \"STRUCT\", \"GRADE\", \"CNDTN\", \"EXTWALL\", \"INTWALL\", \"ROOF\", \"ZIPCODE\", \"ASSESSMENT_NBHD\", \"ASSESSMENT_SUBNBHD\", \"CENSUS_TRACT\", \"CENSUS_BLOCK\", \"WARD\", \"QUADRANT\", \"WAS_REMODELED\"], axis=1)\n",
    "data_col_no_cat = data_col_no_cat.drop([\"HEAT\", \"AC\", \"QUALIFIED\", \"ZIPCODE\", \"ASSESSMENT_NBHD\", \"CENSUS_TRACT\", \"WARD\", \"QUADRANT\", \"WAS_REMODELED\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data (x and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_row = data_row.drop([\"PRICE\"], axis=1)\n",
    "x_row_one_hot = data_row_one_hot.drop([\"PRICE\"], axis=1)\n",
    "x_row_no_cat = data_row_no_cat.drop([\"PRICE\"], axis=1)\n",
    "y_row = data_row[\"PRICE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_col = data_col.drop([\"PRICE\"], axis=1)\n",
    "x_col_one_hot = data_col_one_hot.drop([\"PRICE\"], axis=1)\n",
    "x_col_no_cat = data_col_no_cat.drop([\"PRICE\"], axis=1)\n",
    "y_col = data_col[\"PRICE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data (train and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_size_row = round(data_row.shape[0] * 0.7)\n",
    "split_size_col = round(data_col.shape[0] * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_row_train, x_row_test = np.split(x_row, [split_size_row], axis = 0)\n",
    "x_row_one_hot_train, x_row_one_hot_test = np.split(x_row_one_hot, [split_size_row], axis = 0)\n",
    "x_row_no_cat_train, x_row_no_cat_test = np.split(x_row_no_cat, [split_size_row], axis = 0)\n",
    "y_row_train, y_row_test = np.split(y_row, [split_size_row], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_col_train, x_col_test = np.split(x_col, [split_size_col], axis = 0)\n",
    "x_col_one_hot_train, x_col_one_hot_test = np.split(x_col_one_hot, [split_size_col], axis = 0)\n",
    "x_col_no_cat_train, x_col_no_cat_test = np.split(x_col_no_cat, [split_size_col], axis = 0)\n",
    "y_col_train, y_col_test = np.split(y_col, [split_size_col], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start trianing\")\n",
    "linreg_row = LinearRegression(n_jobs = -1, normalize = True)\n",
    "linreg_row.fit(x_row_no_cat_train, y_row_train)\n",
    "print(\"End training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start trianing\")\n",
    "linreg_col = LinearRegression(n_jobs = -1, normalize = True)\n",
    "linreg_col.fit(x_col_no_cat_train, y_col_train)\n",
    "print(\"End training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_row_lin_pred = linreg_row.predict(x_row_no_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_col_lin_pred = linreg_col.predict(x_col_no_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_lin_score = linreg_row.score(x_row_no_cat_test, y_row_test)\n",
    "row_lin_msqe = mean_squared_error(y_row_test, y_row_lin_pred)\n",
    "print(\"R2 score for the row dataset: \" + str(row_lin_score))\n",
    "print(\"Mean squared error for the row dataset: \" + str(row_lin_msqe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "\n",
    "plt.scatter(y_row_test, y_row_lin_pred)\n",
    "plt.xlabel(\"Prices: $Y_i$\")\n",
    "plt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\n",
    "plt.title(\"Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_lin_score = linreg_col.score(x_col_no_cat_test, y_col_test)\n",
    "col_lin_msqe = mean_squared_error(y_col_test, y_col_lin_pred)\n",
    "print(\"R2 score for the column dataset: \" + str(col_lin_score))\n",
    "print(\"Mean squared error for the row dataset: \" + str(col_lin_msqe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "\n",
    "plt.scatter(y_col_test, y_col_lin_pred)\n",
    "plt.xlabel(\"Prices: $Y_i$\")\n",
    "plt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\n",
    "plt.title(\"Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Logistic Regression (dataset is to complex for my computer to compute this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start training\")\n",
    "logreg_row = LogisticRegression(n_jobs = -1, solver = \"sag\", max_iter=100000)\n",
    "logreg_row.fit(x_row_no_cat_train, y_row_train)\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Start training\")\n",
    "logreg_col = LogisticRegression(n_jobs = -1, solver = \"sag\", max_iter=100000, normalize = True)\n",
    "logreg_col.fit(x_col_train, y_col_train)\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_row_log_pred = logreg_row.predict(x_row_no_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_col_log_pred = logreg_col.predict(x_col_no_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_log_score = logreg_row.score(x_row_no_cat_test, y_row_test)\n",
    "print(\"R2 score for the row dataset: \" + str(row_log_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_row_test, y_row_log_pred)\n",
    "plt.xlabel(\"Prices: $Y_i$\")\n",
    "plt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\n",
    "plt.title(\"Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_log_score = logreg_col.score(x_col_no_cat_test, y_col_test)\n",
    "print(\"R2 score for the column dataset: \" + str(col_log_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_col_test, y_col_lin_pred)\n",
    "plt.xlabel(\"Prices: $Y_i$\")\n",
    "plt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\n",
    "plt.title(\"Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the model\n",
    "# print(\"Start training\")\n",
    "# knn_row = KNeighborsClassifier(n_neighbors = 2, n_jobs = -1)\n",
    "# knn_row.fit(x_row_one_hot_train, y_row_train)\n",
    "# print(\"Finished training\")\n",
    "\n",
    "# # predict the test data\n",
    "# y_row_knn_pred = knn_row.predict(x_row_one_hot_test)\n",
    "\n",
    "# # output\n",
    "# print(classification_report(y_row_test, y_row_knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the model\n",
    "# print(\"Start training\")\n",
    "# knn_col = KNeighborsClassifier(n_neighbors = 2, n_jobs = -1)\n",
    "# knn_col.fit(x_col_one_hot_train, y_col_train)\n",
    "# print(\"Finished training\")\n",
    "\n",
    "# # predict the test data\n",
    "# y_col_knn_pred = knn_col.predict(x_col_one_hot_test)\n",
    "\n",
    "# # output\n",
    "# print(classification_report(y_col_test, y_col_knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 500, num = 10)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [1, 20]}\n",
    "\n",
    "print(\"Start training\")\n",
    "RFR = RandomForestRegressor(n_jobs = -1)\n",
    "RFR_cv = RandomizedSearchCV(RFR, param_dist)\n",
    "RFR_cv.fit(x_row_one_hot_train, y_row_train)\n",
    "print(\"Finished training\")\n",
    "evaluate(RFR_cv.best_estimator_, x_row_one_hot_test, y_row_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_row_rf_predict = RFR.predict(x_row_one_hot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "\n",
    "plt.scatter(y_row_test, y_row_rf_predict)\n",
    "plt.xlabel(\"Prices: $Y_i$\")\n",
    "plt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\n",
    "plt.title(\"Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
